\chapter{Método}
\label{chapter:method}

Este capítulo descreve a elaboração de classificadores de sentimento de tweets
usando técnicas de processamento de linguagem natural e ciência de redes.
Serão detalhados as etapas de coleta de base de dados, as figuras de mérito
utilizadas nas avaliações dos modelos e o processo de treinamento dos
algoritmos.

\section{Bases de Dados}

Serão utilizadas duas bases de dados nesse trabalho, uma de treinamento e uma de
teste.
As bases serão formadas por tweets captados utilizando a
API~\footnote{https://developer.twitter.com/en/docs/twitter-api} do Twitter,
a qual fornece amostras de mensagens que contenham algumas palavras-chave
de eventos de interesse.

As mensagens de texto receberão alguns pré-processamentos antes de formarem as
bases de dados.
O primerio passo será aplicar a tokenização, quebrando a mensagem em sequência
de palavras e removendo as pontuações.
Posteriormente as palavras serão postas em forma minúscula.
Por fim, menções a usuários e hiperlinks serão substituidos por tokens especiais.

Tendo objetivo de diminuir o custo de desenvolvimento do classificador textual será
adotado o método de anotação distante descrito por~\citet{go09} para formação da
base de dados de treinamento, usando emoticons como característica de anotação.
Serão selecionados manualmente emoticons positivos e negativos dentre os mais
frequentes nos textos captados.
As mensagens que possuírem um ou mais dos emoticons selecionados serão
categorizadas com a classe correspondente na base de treinamento.
Para remover possíveis ambiguidades, serão removidos da base os textos que
possuirem mais do que uma categoria.
Além disso, os emoticons utilizados na supervisão distante foram removidos dos
textos de treinamento para evitar a introdução de vies no classificador.
A Tabela~\ref{tab:emoticons} mostra os emoticons escolhidos.
%: TODO jogar essa tabela para resultados

\begin{table}[h]
    \begin{center}
        \begin{tabular}{| l | c |}
        \hline
        \textbf{Classe} & \textbf{Emoticons} \\ \hline
        Positiva &
            \includegraphics[height=1em]{images/emojis/2764}
            \includegraphics[height=1em]{images/emojis/1F602}
            %\includegraphics[height=1em]{images/emojis/1F5A4}
            %\includegraphics[height=1em]{images/emojis/1F923}
            \includegraphics[height=1em]{images/emojis/1F60D}
            \includegraphics[height=1em]{images/emojis/2665}
            %\includegraphics[height=1em]{images/emojis/1F970}
            \includegraphics[height=1em]{images/emojis/1F605}
            \includegraphics[height=1em]{images/emojis/1F601}
            %\includegraphics[height=1em]{images/emojis/1F92D}
            \includegraphics[height=1em]{images/emojis/1F618}
            \includegraphics[height=1em]{images/emojis/1F609}
            \includegraphics[height=1em]{images/emojis/1F496}
            \includegraphics[height=1em]{images/emojis/1F495}
            \includegraphics[height=1em]{images/emojis/1F606}
            %\includegraphics[height=1em]{images/emojis/1F973}
            \includegraphics[height=1em]{images/emojis/1F499}
            \includegraphics[height=1em]{images/emojis/1F389}
            \includegraphics[height=1em]{images/emojis/1F61D}
            \includegraphics[height=1em]{images/emojis/1F49A}
            \includegraphics[height=1em]{images/emojis/1F49C}
            %\includegraphics[height=1em]{images/emojis/2763}
            \includegraphics[height=1em]{images/emojis/1F60A}
            \includegraphics[height=1em]{images/emojis/1F60B}
            %\includegraphics[height=1em]{images/emojis/1F917}
        \\ \hline
        Negativa &
            \includegraphics[height=1em]{images/emojis/1F62D}
            \includegraphics[height=1em]{images/emojis/1F645}
            %\includegraphics[height=1em]{images/emojis/1F926}
            \includegraphics[height=1em]{images/emojis/1F621}
            \includegraphics[height=1em]{images/emojis/1F614}
            %\includegraphics[height=1em]{images/emojis/1F92C}
            %\includegraphics[height=1em]{images/emojis/1F92E}
            \includegraphics[height=1em]{images/emojis/1F629}
            \includegraphics[height=1em]{images/emojis/1F622}
            \includegraphics[height=1em]{images/emojis/1F620}
            \includegraphics[height=1em]{images/emojis/1F612}
            \includegraphics[height=1em]{images/emojis/1F624}
            \includegraphics[height=1em]{images/emojis/1F494}
            \includegraphics[height=1em]{images/emojis/1F62A}
            \includegraphics[height=1em]{images/emojis/1F625}
            \includegraphics[height=1em]{images/emojis/1F62B}
            \includegraphics[height=1em]{images/emojis/1F630}
        \\ \hline
        \end{tabular}
        \caption{Emoticons selecionados para aplicação de supervisão distante.}
        \label{tab:emoticons}
    \end{center}
\end{table}

A base de testes será composta de tweets anotados manualmente.
Esta será utilizada para avaliar os modelos treinados com os metodos
semi-supervisionados.
Para esta finalidade, serão reservadas mensagens de um conjunto de usuários
selecionados aleatóriamente para compor essa base.
Esta separação é importante para evitar vies pois apesar de os métodos de
representação de usuários serem não supervisionados, como será descrito na
Seção~\ref{sec:development}, essa representação será utilizada no treinamento do
classificador.
As mensagens destes usuários serão disponibilizadas para anotação utilizando a
ferramenta Doccano~\footnote{https://github.com/doccano/doccano}.
Por fim, as mensagens anotadas comporão a base de dados de teste.

\section{Figuras de Mérito}

A avaliação dos algoritmos aplicados nestas bases será feita utilizando as figuras
de mérito descritas nessa seção.

Levando em consideração o desbalanceamento de classes das bases de dados não é
adequado a aplicação da acurácia pois esta favoreceria a classe majoritariamente
presente nas bases.
Como alternativa será adotada a área sob a curva ROC (\textit{receiver operating
characteristic}).
A curva ROC apresenta a relação entre probabilidade de detecção e falso alarme
para diferentes patamares de decisão de classificadores binários.
A área sob a curva ROC é uma medida que agrupa esse conjunto de taxas em um
número único, que representa o modelo em todos possíveis pontos de operação.

Como o objetivo abordado não apresenta um ponto de operação pré-definido, esse
também pode ser definido pela otimização de uma figura de mérito.
Desta forma, A seleção do limiar do classificador treinado será feita a partir do
índice SP~\cite{ciodaro12}.
Este índice consiste na média geométrica entre os pontos de média geométrica e
média aritmética entre a probabilidade de detecção da classe positiva $P_c$ e a
probabilidade de não obtenção de falso alarme $P_{nc}$, como mostra a
Equação~\ref{eq:sp}.

\begin{equation} \label{eq:sp}
    SP = \sqrt{\sqrt{P_c P_{nc}} \left(\frac{P_c + P_{nc}}{2}\right)}
\end{equation}

\section{Desenvolvimento}
\label{sec:development}

O objetivo deste trabalho é desenvolver classificadores de análise de sentimento
de tweets sem a necessidade de anotações de dados e que explorem a multi-modalidade
do problema.
Desta forma, serão dívidos os experimentos em duas etapas.
A primeira considerando apenas o texto das mensagens, serão avaliadas as técnicas
descritas no Capítulo~\ref{chapter:nlp}.
Posteriormente, serão utilizadas as representações das mensagens e as
representações da rede de usuários conjuntamente.
Desta forma analisaremos se a adição de informação do usuário infere em alguma
vantagem de performance no classificador.

\subsection{Classificadores de Processamento de Linguagem Natural}
\label{sec:nlp-classifier}

Seguindo os classificadores apresentados no Capítulo~\ref{chapter:nlp}, o
primeiro algoritmo aplicado será o Naive Bayes.
As mensagens serão representadas por Bag-of-Words e, por isso, será utilizado
Naive Bayes com distribuição multinomial.
Será utilizada a suavização de Laplace como regularizador do modelo.
O valor do parâmetro de suavização será selecionado de maneira a maximizar a
área sob a curva ROC (AUC).
A validação cruzada por K-partições servirá para maximizar esse valor, sendo
selecionadas 10 partições.

Posteriormente será treinado o classificador de SVM, também com representação de
Bag-of-Words.
Dado o grande volume de dados e a complexidade computacional será utilizado a
variação de SVM por método de gradiente como proposto por \citet{suykens99}.
Neste caso, será utilizada regularização $L_2$, assim como no classificador de
Naive Bayes, este parâmetro será selecionado por validação cruzada de
K-partições de 10 partições, de maneira a maximizar a AUC.
Tanto o modelo de Naive Bayes quanto o SVM foram treinados utilizando as
implementações disponibilizadas pela biblioteca Scikit-Learn~\cite{sklearn11}.

Para os modelos CNN e LSTM usaremos como representação o Word2Vec.
O treinamento do Word2Vec será feito a partir das mensagens amostradas do
Twitter, as mesmas mensagens utilizadas para formar a base de dados de treinamento
por supervisão distante, seguindo os mesmos pré-processamentos.
O modelo treinado terá tamanho de janela 5 e dimensionalidade 100 do vetor de
representação.
O treinamento será feito utilizando a biblioteca Gensim~\cite{rehurek10}.

O treinamento dos classificadores de \textit{Deep Learning} por CNN e LSTM serão
treinados de formas similares.
Ambos terão como entrada os textos representados por Word2Vec.
Nestes classificadores, além das camadas convolucionais e LSTM, respectivamente,
uma camada será adicionada com um único neurônio para realização da
classificação.
Os hiperparâmetros dos modelos serão obtidos por busca em \textit{grid}.
Como estes métodos tem alto custo computacional, não será utilizada a validação
de K-partições.
Será selecionado aleatoriamente um conjunto de validação composto por 20\% dos
dados de treinamento, sendo este usado para seleção dos hiperparâmetros.
Para reduzir o efeito de \textit{overfitting} será aplicado o \textit{early
stopping}.
Uma vez selecionado o conjunto de hiperparâmetros, os modelos serão retreinados
um conjunto de vezes para se estimar a média e desvio padrão de desempenho de cada
técnica.

Por fim, será avaliada a representação de palavras pela técnica ELMo.
Como este modelo contêm um número elevado de parâmetros, será utilizado um
conjunto de pesos pré-treinados~\footnote{https://allennlp.org/elmo}, os quais
foram treinados em textos em português retirados da
Wikipedia~\footnote{https://www.wikipedia.org}.
O modelo gera vetores de representações de tamanho $1024$ e foi treinado com
duas camadas.
Será utilizada apenas a camada superior do modelo, dado que para tarefa de
análise de sentimento se faz mais relevante a informação semântica das mensagens.
Em conjunto com essa representação, será utilizado o modelo de CNN para
classificação do texto.
Este seguirá o mesmo método do anterior, otimizando hiperparâmetros por busca em 
\textit{grid} e usando uma parte dos dados para validação.

Em virtude do alto custo computacional do modelo BERT apresentado no
Capítulo~\ref{chapter:nlp} não será possível o treinamento do mesmo para
comparação, apesar dos bons resultados obtidos em seu artigo de referência.

Dessa forma se concluirá a comparação de desempenho dos algoritmos clássicos
de processamento de linguagem natural com as técnicas neurais desenvolvidas no
decorrer da última década.
Neste estágio foram analisadas apenas os dados textuais das mensagens, a seguir
será apresentado o método que unificará a informação provinda dos textos com as
informações obtidas do usuário.

% dizer como o grafo é representado: grafo homogenio de usuarios, arestas
% direcionais de retweets com peso (que dependendo do modelo pode ser
% considerado ou nao)
